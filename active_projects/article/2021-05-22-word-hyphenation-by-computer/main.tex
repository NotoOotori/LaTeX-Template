\documentclass[11pt]{article}
% \usetheme{Berlin}

\title{Word Hy-phen-a-tion by Com-put-er}
\author{Chen Xuyang}
% date
\day=27\relax
\month=5\relax
\year=2021\relax

% page size https://tex.stackexchange.com/questions/75646/proper-page-size-for-slides
\usepackage[%
  papersize={12.8cm,9.6cm},
  hmargin=1cm,%
  vmargin=1cm,%
  head=0.5cm,% might be changed later
  headsep=0pt,%
  foot=0.5cm,% might be changed later
  top=1cm,
  bottom=1cm,
  ]{geometry}

\pagestyle{empty}

% \usepackage{ragged2e}
% \let\raggedright=\RaggedRight

\hyphenpenalty=-200% encourage hyphenation -200

\usepackage{metalogo}

\newcommand{\pat}[1]{\texttt{#1}}

\newenvironment{example}{%
  \begin{quotation}%
    \setlength{\parindent}{-\parindent}%
    \hyphenpenalty=10000%
    \ttfamily%
    \hspace{2.75\parindent}
  }{\end{quotation}}

\usepackage[dvipsnames]{xcolor}
\newcommand\bh{\textcolor{red}{-}}

\usepackage{fontspec}
\newfontfamily\textipa{Doulos_SIL_Regular.ttf}

\begin{document}
  \maketitle\thispagestyle{empty}\clearpage

  Hello everybody! My name is Chen Xuyang, and I'm a senior from the School of Mathematical Science. Today I'm going to present the Ph.D. thesis ``Word Hyphenation by Computer" of Franklin M. Liang -- a student of the famous Donald E. Knuth -- written in August 1983. The thesis talks about the word hyphenation algorithm for the \TeX 82 typesetting system.

  The first question is: How is the paper related to our GEP course? Well, the algorithm deals with the separation of a word into written syllables in American English, which are not exactly the spoken ones, but they are closely related. So we may achieve a new understanding of syllabification through studying the paper. In this talk, I will briefly introduce the basic idea of hyphenation, and provide some examples to show how magic the algorithm is. Note that the slide has been specially typeset so that it hyphenates words much more often than usual, so the reader can find many examples of word breaks and can compare them with spoken syllabification.

  Hyphenation is briefly a data compression problem, where we are provided with a dictionary with allowable division points and try to reduce the redundancy among them. To solve the problem, the paper emphasizes on the concept named \emph{pattern}.

  A pattern is simply a string of letters that can tell us available break points when such string is matched in a word. For example, the pattern \pat{-tion} means one may hyphenate before the \pat{t} when \pat{tion} is shown up in a word.

  One may end up with plenty of exceptions after applying some `good' patterns, e.g. the pattern \pat{-tion} fails on the word \pat{cation}, but there are still similarities among these exceptions. So the author comes up with the idea of \emph{inhibiting} patterns, that shows where a hyphen cannot be placed.

  Actually the paper uses five alternating levels of hyphenating and inhibiting patterns. The patterns are generated by a computer program written by the author, where a number of 4462 patterns have been marked. With these patterns, one can detect 89\% of available break points among all 31036 words in Webster's Pocket Dictionary, with essentially no errors, where the exceptional list contains only 14 words. It uses only 5\% of the storage of the original dictionary, and the searching for the patterns is very fast.

  And now let's see how it works through the following examples. For each word, we show the patterns that applies, the resulting hyphenation values and the hyphenation obtained. Note that the digits appearing between the letters of a pattern indicate the hyphenation level. If more than one hyphenation value is specified for a given intercharacter position, then only the higher value counts. And finally the position is an allowable hyphen point if and only if the final value is odd.

  \begin{example}
    hyphenation\\ hy3ph he2n hena4 hen5at 1na n2at 1tio 2io\\
    hy3phe2n5a4t2ion hy-phen-ation

    concatenation\\ o2n on1c 1ca 1na n2at 1tio 2io\\
    co2n1cate1n2a1t2ion con-cate-na-tion

    supercalifragilisticexpialidocious\\
      u1pe r1c 1ca al1i ag1i gil4 il1i il4ist is1ti st2i s1tic 1exp x3p pi3a 2i1a i2al 2id 1do 1ci 2io 2us\\
      su1per1cal1ifrag1il4is1t2ic1ex3p2i3al2i1do1c2io2us\\
      su-per-cal-ifrag-ilis-tic-ex-pi-ali-do-cious\\
      su-per-cal-i\bh frag-i\bh lis-tic-ex-pi-a\bh li-do-cious\\
      \textipa{/sjuːpəˌkælɪˌfrædʒɪˌlɪstɪkˌekspɪˌælɪˈdəʊʃəs/}
  \end{example}

  English is a language full of exceptions, but computer programs can detect rules with only exceptions from specialist technical terms. Hope we can learn something from these patterns. That's all of my presentation. Thanks for listening!
\end{document}

% 31036 words
% consideration
% cation 阳离子
% co-a-lesce
% ho-mol-o-gous l5ogo
% be-tray-al
% bach-e-lor
% ˌ ˈ
